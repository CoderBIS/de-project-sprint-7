{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d3dc1f",
   "metadata": {},
   "source": [
    "# Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9317b6",
   "metadata": {},
   "source": [
    "Коллеги из другого проекта по просьбе нашей команды начали вычислять координаты событий (сообщений, подписок, реакций, регистраций), которые совершили пользователи соцсети. Значения координат будут появляться в таблице событий. Пока определяется геопозиция только исходящих сообщений, но уже сейчас можно начать разрабатывать новый функционал. \n",
    "В продукт планируют внедрить систему рекомендации друзей. Приложение будет предлагать пользователю написать человеку, если пользователь и адресат:\n",
    "* состоят в одном канале,\n",
    "* раньше никогда не переписывались,\n",
    "* находятся не дальше 1 км друг от друга.\n",
    "При этом команда хочет лучше изучить аудиторию соцсети, чтобы в будущем запустить монетизацию. Для этого было решено провести геоаналитику:\n",
    "* Выяснить, где находится большинство пользователей по количеству сообщений, лайков и подписок из одной точки.\n",
    "* Посмотреть, в какой точке Австралии регистрируется больше всего новых пользователей.\n",
    "* Определить, как часто пользователи путешествуют и какие города выбирают.\n",
    "Благодаря такой аналитике в соцсеть можно будет вставить рекламу: приложение сможет учитывать местонахождение пользователя и предлагать тому подходящие услуги компаний-партнёров. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d64a9d7",
   "metadata": {},
   "source": [
    "## Создать витрину в разрезе пользователей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f3af7",
   "metadata": {},
   "source": [
    "Определите, в каком городе было совершено событие. С этим нам поможет список городов из файла geo.csv. В нём указаны координаты центра города.\n",
    "\n",
    "Найдите расстояние от координаты отправленного сообщения до центра города. Событие относится к тому городу, расстояние до которого наименьшее.\n",
    "\n",
    "Витрина должна содержать следующие атрибуты:\n",
    "\n",
    "* user_id — идентификатор пользователя.\n",
    "* act_city — актуальный адрес. Это город, из которого было отправлено последнее сообщение.\n",
    "* home_city — домашний адрес. Это последний город, в котором пользователь был дольше 27 дней.\n",
    "* travel_count — количество посещённых городов. Если пользователь побывал в каком-то городе повторно, то это считается за отдельное посещение.\n",
    "* travel_array — список городов в порядке посещения (не понял как реализовать).\n",
    "* TIME_UTC — время в таблице событий. Указано в UTC+0.\n",
    "* timezone — актуальный адрес. Атрибуты содержатся в виде Australia/Sydney."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb28bc7",
   "metadata": {},
   "source": [
    "Создадим подключение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b7069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HADOOP_CONF_DIR'] = '/etc/hadoop/conf'\n",
    "os.environ['YARN_CONF_DIR'] = '/etc/hadoop/conf'\n",
    " \n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "import datetime\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"yarn\") \\\n",
    "        .config(\"spark.driver.cores\", \"2\") \\\n",
    "        .config(\"spark.driver.memory\", \"4g\") \\\n",
    "        .appName(\"test1337\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848039bd",
   "metadata": {},
   "source": [
    "Откроем файл geo.\n",
    "Я не знал, как в PySpark запятую в координатах заменить точкой, чтобы присвоить корректный тип данных и пересохранил файл с точкой через pandas и назвал его geo_2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32014ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>-33.8650</td>\n",
       "      <td>151.2094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>-37.8136</td>\n",
       "      <td>144.9631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>-27.4678</td>\n",
       "      <td>153.0281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Perth</td>\n",
       "      <td>-31.9522</td>\n",
       "      <td>115.8589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>-34.9289</td>\n",
       "      <td>138.6011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Gold Coast</td>\n",
       "      <td>-28.0167</td>\n",
       "      <td>153.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Cranbourne</td>\n",
       "      <td>-38.0996</td>\n",
       "      <td>145.2834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Canberra</td>\n",
       "      <td>-35.2931</td>\n",
       "      <td>149.1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>-32.9167</td>\n",
       "      <td>151.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Wollongong</td>\n",
       "      <td>-34.4331</td>\n",
       "      <td>150.8831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>-38.1500</td>\n",
       "      <td>144.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>-42.8806</td>\n",
       "      <td>147.3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Townsville</td>\n",
       "      <td>-19.2564</td>\n",
       "      <td>146.8183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Ipswich</td>\n",
       "      <td>-27.6167</td>\n",
       "      <td>152.7667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Cairns</td>\n",
       "      <td>-16.9303</td>\n",
       "      <td>145.7703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Toowoomba</td>\n",
       "      <td>-27.5667</td>\n",
       "      <td>151.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Darwin</td>\n",
       "      <td>-12.4381</td>\n",
       "      <td>130.8411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Ballarat</td>\n",
       "      <td>-37.5500</td>\n",
       "      <td>143.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Bendigo</td>\n",
       "      <td>-36.7500</td>\n",
       "      <td>144.2667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Launceston</td>\n",
       "      <td>-41.4419</td>\n",
       "      <td>147.1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Mackay</td>\n",
       "      <td>-21.1411</td>\n",
       "      <td>149.1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Rockhampton</td>\n",
       "      <td>-23.3750</td>\n",
       "      <td>150.5117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Maitland</td>\n",
       "      <td>-32.7167</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Bunbury</td>\n",
       "      <td>-33.3333</td>\n",
       "      <td>115.6333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id         city      lat       lng\n",
       "0    1       Sydney -33.8650  151.2094\n",
       "1    2    Melbourne -37.8136  144.9631\n",
       "2    3     Brisbane -27.4678  153.0281\n",
       "3    4        Perth -31.9522  115.8589\n",
       "4    5     Adelaide -34.9289  138.6011\n",
       "5    6   Gold Coast -28.0167  153.4000\n",
       "6    7   Cranbourne -38.0996  145.2834\n",
       "7    8     Canberra -35.2931  149.1269\n",
       "8    9    Newcastle -32.9167  151.7500\n",
       "9   10   Wollongong -34.4331  150.8831\n",
       "10  11      Geelong -38.1500  144.3500\n",
       "11  12       Hobart -42.8806  147.3250\n",
       "12  13   Townsville -19.2564  146.8183\n",
       "13  14      Ipswich -27.6167  152.7667\n",
       "14  15       Cairns -16.9303  145.7703\n",
       "15  16    Toowoomba -27.5667  151.9500\n",
       "16  17       Darwin -12.4381  130.8411\n",
       "17  18     Ballarat -37.5500  143.8500\n",
       "18  19      Bendigo -36.7500  144.2667\n",
       "19  20   Launceston -41.4419  147.1450\n",
       "20  21       Mackay -21.1411  149.1861\n",
       "21  22  Rockhampton -23.3750  150.5117\n",
       "22  23     Maitland -32.7167  151.5500\n",
       "23  24      Bunbury -33.3333  115.6333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"geo.csv\", sep=';', decimal=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92309a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('geo_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "592ce5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 227:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------+--------+\n",
      "|id |city       |lat     |lng     |\n",
      "+---+-----------+--------+--------+\n",
      "|1  |Sydney     |-33.865 |151.2094|\n",
      "|2  |Melbourne  |-37.8136|144.9631|\n",
      "|3  |Brisbane   |-27.4678|153.0281|\n",
      "|4  |Perth      |-31.9522|115.8589|\n",
      "|5  |Adelaide   |-34.9289|138.6011|\n",
      "|6  |Gold Coast |-28.0167|153.4   |\n",
      "|7  |Cranbourne |-38.0996|145.2834|\n",
      "|8  |Canberra   |-35.2931|149.1269|\n",
      "|9  |Newcastle  |-32.9167|151.75  |\n",
      "|10 |Wollongong |-34.4331|150.8831|\n",
      "|11 |Geelong    |-38.15  |144.35  |\n",
      "|12 |Hobart     |-42.8806|147.325 |\n",
      "|13 |Townsville |-19.2564|146.8183|\n",
      "|14 |Ipswich    |-27.6167|152.7667|\n",
      "|15 |Cairns     |-16.9303|145.7703|\n",
      "|16 |Toowoomba  |-27.5667|151.95  |\n",
      "|17 |Darwin     |-12.4381|130.8411|\n",
      "|18 |Ballarat   |-37.55  |143.85  |\n",
      "|19 |Bendigo    |-36.75  |144.2667|\n",
      "|20 |Launceston |-41.4419|147.145 |\n",
      "|21 |Mackay     |-21.1411|149.1861|\n",
      "|22 |Rockhampton|-23.375 |150.5117|\n",
      "|23 |Maitland   |-32.7167|151.55  |\n",
      "|24 |Bunbury    |-33.3333|115.6333|\n",
      "+---+-----------+--------+--------+\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lng: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "geo_2 = spark.read.csv(\"/user/antonnnbis/tmp/geo_2.csv\", sep=\",\", inferSchema=True, header=True)\n",
    "geo_2.show(n = 30, truncate = False)\n",
    "geo_2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c49a7c",
   "metadata": {},
   "source": [
    "Создал справочник для заполнения атрибута timezone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d9687d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|           timezone|city_id|\n",
      "+-------------------+-------+\n",
      "|   Australia/Sydney|      1|\n",
      "|Australia/Melbourne|      2|\n",
      "| Australia/Brisbane|      3|\n",
      "|    Australia/Perth|      4|\n",
      "| Australia/Adelaide|      5|\n",
      "| Australia/Brisbane|      6|\n",
      "|Australia/Melbourne|      7|\n",
      "|   Australia/Sydney|      8|\n",
      "|   Australia/Sydney|      9|\n",
      "|   Australia/Sydney|     10|\n",
      "|Australia/Melbourne|     11|\n",
      "|   Australia/Hobart|     12|\n",
      "| Australia/Brisbane|     13|\n",
      "| Australia/Brisbane|     14|\n",
      "| Australia/Brisbane|     15|\n",
      "| Australia/Brisbane|     16|\n",
      "|   Australia/Darwin|     17|\n",
      "|Australia/Melbourne|     18|\n",
      "|Australia/Melbourne|     19|\n",
      "|   Australia/Hobart|     20|\n",
      "| Australia/Brisbane|     21|\n",
      "| Australia/Brisbane|     22|\n",
      "|   Australia/Sydney|     23|\n",
      "|    Australia/Perth|     24|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_geo = [('Australia/Sydney', 1),\n",
    "        ('Australia/Melbourne', 2),\n",
    "        ('Australia/Brisbane', 3),\n",
    "        ('Australia/Perth', 4),\n",
    "        ('Australia/Adelaide', 5),\n",
    "        ('Australia/Brisbane', 6),\n",
    "        ('Australia/Melbourne', 7),\n",
    "        ('Australia/Sydney', 8),\n",
    "        ('Australia/Sydney', 9),\n",
    "        ('Australia/Sydney', 10),\n",
    "        ('Australia/Melbourne', 11),\n",
    "        ('Australia/Hobart', 12),\n",
    "        ('Australia/Brisbane', 13),\n",
    "        ('Australia/Brisbane', 14),\n",
    "        ('Australia/Brisbane', 15),\n",
    "        ('Australia/Brisbane', 16),\n",
    "        ('Australia/Darwin', 17),\n",
    "        ('Australia/Melbourne', 18),\n",
    "        ('Australia/Melbourne', 19),\n",
    "        ('Australia/Hobart', 20),\n",
    "        ('Australia/Brisbane', 21),\n",
    "        ('Australia/Brisbane', 22),\n",
    "        ('Australia/Sydney', 23),\n",
    "        ('Australia/Perth', 24)\n",
    "]\n",
    "\n",
    "columns_geo = ['timezone', 'city_id']\n",
    "df_timezone = spark.createDataFrame(data=data_geo, schema=columns_geo)\n",
    "df_timezone.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200a0f3",
   "metadata": {},
   "source": [
    "Соединил созданный справочник с таблицей geo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5546f9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 18:31:41,432 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 230.0 (TID 21365, rc1a-dataproc-d-5w4oxa2s5b8foehs.mdb.yandexcloud.net, executor 5): java.io.EOFException\n",
      "\tat java.io.DataInputStream.readInt(DataInputStream.java:392)\n",
      "\tat org.apache.spark.api.python.PythonWorkerFactory.createSocket$1(PythonWorkerFactory.scala:120)\n",
      "\tat org.apache.spark.api.python.PythonWorkerFactory.liftedTree1$1(PythonWorkerFactory.scala:136)\n",
      "\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:135)\n",
      "\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)\n",
      "\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:131)\n",
      "\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:462)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:465)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------+--------+-------------------+\n",
      "| id|       city|     lat|     lng|           timezone|\n",
      "+---+-----------+--------+--------+-------------------+\n",
      "|  1|     Sydney| -33.865|151.2094|   Australia/Sydney|\n",
      "|  2|  Melbourne|-37.8136|144.9631|Australia/Melbourne|\n",
      "|  3|   Brisbane|-27.4678|153.0281| Australia/Brisbane|\n",
      "|  4|      Perth|-31.9522|115.8589|    Australia/Perth|\n",
      "|  5|   Adelaide|-34.9289|138.6011| Australia/Adelaide|\n",
      "|  6| Gold Coast|-28.0167|   153.4| Australia/Brisbane|\n",
      "|  7| Cranbourne|-38.0996|145.2834|Australia/Melbourne|\n",
      "|  8|   Canberra|-35.2931|149.1269|   Australia/Sydney|\n",
      "|  9|  Newcastle|-32.9167|  151.75|   Australia/Sydney|\n",
      "| 10| Wollongong|-34.4331|150.8831|   Australia/Sydney|\n",
      "| 11|    Geelong|  -38.15|  144.35|Australia/Melbourne|\n",
      "| 12|     Hobart|-42.8806| 147.325|   Australia/Hobart|\n",
      "| 13| Townsville|-19.2564|146.8183| Australia/Brisbane|\n",
      "| 14|    Ipswich|-27.6167|152.7667| Australia/Brisbane|\n",
      "| 15|     Cairns|-16.9303|145.7703| Australia/Brisbane|\n",
      "| 16|  Toowoomba|-27.5667|  151.95| Australia/Brisbane|\n",
      "| 17|     Darwin|-12.4381|130.8411|   Australia/Darwin|\n",
      "| 18|   Ballarat|  -37.55|  143.85|Australia/Melbourne|\n",
      "| 19|    Bendigo|  -36.75|144.2667|Australia/Melbourne|\n",
      "| 20| Launceston|-41.4419| 147.145|   Australia/Hobart|\n",
      "| 21|     Mackay|-21.1411|149.1861| Australia/Brisbane|\n",
      "| 22|Rockhampton| -23.375|150.5117| Australia/Brisbane|\n",
      "| 23|   Maitland|-32.7167|  151.55|   Australia/Sydney|\n",
      "| 24|    Bunbury|-33.3333|115.6333|    Australia/Perth|\n",
      "+---+-----------+--------+--------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 18:31:41,683 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 231.0 (TID 21368, rc1a-dataproc-d-5w4oxa2s5b8foehs.mdb.yandexcloud.net, executor 5): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:536)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:525)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:643)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:462)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:465)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.EOFException\n",
      "\tat java.io.DataInputStream.readInt(DataInputStream.java:392)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:628)\n",
      "\t... 23 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "geo = geo_2.join(df_timezone, geo_2.id == df_timezone.city_id, how='inner').drop(df_timezone.city_id)\n",
    "geo.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f470022",
   "metadata": {},
   "source": [
    "Ниже код для прочтения всех исторических данных, но у меня это все обрабатывалось долго и неудобно было с этим работать - я ограничил данные 10-ю днями, когда все заработает, можно будет повторить процесс на всех данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8e7b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 14:02:09,335 WARN datasources.SharedInMemoryCache: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.\n"
     ]
    }
   ],
   "source": [
    "#df_messages = spark.read\\\n",
    "#    .parquet(\"/user/master/data/geo/events\")\\\n",
    "#    .where(\"event_type='message'\")\\\n",
    "#    .select(F.col(\"event.message_from\").alias(\"user\"),\n",
    "#                F.col(\"event.message_id\").alias(\"message\"),\n",
    "#                F.col(\"event_type\").alias(\"event_type\"),\n",
    "#                F.col(\"lat\").alias(\"lat\"),\n",
    "#                F.col(\"lon\").alias(\"lon\"),\n",
    "#                F.col(\"date\").alias(\"date\"),\n",
    "#        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee674be",
   "metadata": {},
   "source": [
    "Функция для прочтения данных по дням:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38f2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_paths(date, depth):\n",
    "    dt = datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "    return [f\"/user/master/data/geo/events/date={(dt-datetime.timedelta(days=x)).strftime('%Y-%m-%d')}\" for x in range(depth)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c2f19",
   "metadata": {},
   "source": [
    "Читаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48c2df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "date = '2022-03-05'\n",
    "depth = 10\n",
    "\n",
    "act_period = input_paths(date, depth)\n",
    "messages = spark.read\\\n",
    "    .option(\"basePath\", \"/user/master/data/geo/events\")\\\n",
    "    .parquet(*act_period)\\\n",
    "    .where(\"event_type='message'\")\n",
    "\n",
    "df_messages = messages\\\n",
    "    .where(\"event_type='message'\")\\\n",
    "    .select(F.col(\"event.message_from\").alias(\"user\"),\n",
    "                F.col(\"event.message_id\").alias(\"message\"),\n",
    "                F.col(\"event_type\").alias(\"event_type\"),\n",
    "                F.col(\"lat\").alias(\"lat\"),\n",
    "                F.col(\"lon\").alias(\"lon\"),\n",
    "                F.col(\"date\").alias(\"date\"),\n",
    "                F.col(\"event.datetime\").alias(\"TIME_UTC\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f2bd3",
   "metadata": {},
   "source": [
    "Объединяем данные путем присвоения всех возможных координат 24-х городов к каждому сообщению:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d79055af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_id(geo_id_max, df):\n",
    "    results = df.withColumn('geo_id', F.lit(1))\n",
    "    for i in range(geo_id_max - 1):\n",
    "        df_geo = df.withColumn('geo_id', F.lit(i+2))\n",
    "        results = df_geo.union(results)\n",
    "    return results.withColumnRenamed(\"lat\", \"lat_1\")\n",
    "\n",
    "df_geo_id = get_geo_id(24, df_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ead0bd",
   "metadata": {},
   "source": [
    "1. Высчитываем расстояние, и оставляем только строки с наименьшим расстоянием rank_dist = 1, что соответствует самуму близкому центру города.\n",
    "2. Группируем пользователей по дате и оставляем только строки с последней датой rank_act_city = 1, что должно соответствовать самому последнему городу, откуда было отправлено сообщение и это считаем актуальным городом.\n",
    "3. Создаем группы городов в зависимости от последовательности прибывания в них и город, в котором пользователь находился 27 и более дней подряд будет считаться городом, где пользователь живет.\n",
    "4. Ранжируем группы дат, соответствующие перемещению пользователя из одного города в другой и максимальное значение ранжирования должно соответствовать количеству перемещений travel_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71d55ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_geo = df_geo_id.join(geo, df_geo_id.geo_id == geo.id, how='inner').drop(geo.id)\\\n",
    "    .withColumnRenamed(\"lat\", \"lat_city\")\\\n",
    "    .withColumnRenamed(\"lng\", \"lon_city\")\\\n",
    "    .withColumnRenamed(\"lat_1\", \"lat\")\n",
    "\n",
    "distance_df = joined_geo.withColumn('distance',\n",
    "                    12742 * F.asin(\n",
    "                        F.sqrt(F.pow(F.sin((F.radians(F.col('lat')) - F.radians(F.col('lat_city')))/F.lit(2)), 2)\\\n",
    "                    + F.cos(F.radians(F.col('lat_city'))) * F.cos(F.radians(F.col('lat')))\\\n",
    "                    * F.pow(F.sin((F.radians(F.col('lon')) - F.radians(F.col('lon_city')))/F.lit(2)), 2)))\n",
    "                               )\n",
    "\n",
    "window_dist = Window().partitionBy('message').orderBy('distance')\n",
    "\n",
    "df_window_dist = distance_df.withColumn(\"rank_dist\", F.row_number().over(window_dist))\n",
    "\n",
    "df_act_city_msg = df_window_dist.select('user', 'message', 'date', 'city', 'TIME_UTC', 'timezone').where(\"rank_dist = 1\")\n",
    "\n",
    "window_date = Window().partitionBy('user').orderBy(F.asc('date'))\n",
    "window_act_city = Window().partitionBy('user').orderBy(F.desc('date'))\n",
    "\n",
    "df_window_date = df_act_city_msg.withColumn(\"rank_date\", F.dense_rank().over(window_date))\n",
    "df_window_act_city = df_act_city_msg.withColumn(\"rank_act_city\", F.row_number().over(window_act_city))\n",
    "\n",
    "df_act_city_date = df_window_act_city.select(F.col(\"user\").alias(\"user\"),\n",
    "                                         F.col(\"city\").alias(\"act_city\"),\n",
    "                                            'TIME_UTC', 'timezone')\\\n",
    "                                        .distinct()\\\n",
    "                                        .where('rank_act_city = 1')\n",
    "\n",
    "df_grp = df_window_date.select('user', 'city', 'date', 'rank_date').distinct()\\\n",
    "                        .withColumn(\"grp_date\", F.col('date') - F.col('rank_date'))\n",
    "\n",
    "\n",
    "dates_users_sities = df_grp.groupBy(F.col('user'), F.col('city'), F.col('grp_date')).count()\n",
    "\n",
    "home_city_df = dates_users_sities.select('user', F.col(\"city\").alias(\"home_city\"))\\\n",
    "                .where('count > 26')\n",
    "\n",
    "view_1 = df_act_city_date.join(home_city_df, df_act_city_date.user == home_city_df.user, how='left')\\\n",
    "        .drop(home_city_df.user)\n",
    "\n",
    "window_travel_count = Window().partitionBy('user').orderBy('grp_date')\n",
    "df_window_travel_count = dates_users_sities.withColumn(\"travel\", F.row_number().over(window_travel_count))\n",
    "df_travel_count = df_window_travel_count.withColumn(\"travel_count\", F.max(\"travel\").over(Window.partitionBy(\"user\")))\n",
    "df_travel_count = df_travel_count.select('user', 'travel_count').distinct()\n",
    "\n",
    "view_1_1 = view_1.join(df_travel_count, view_1.user == df_travel_count.user, how='left').drop(df_travel_count.user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b19d9bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------------------+-------------------+---------+------------+\n",
      "| user|   act_city|           TIME_UTC|           timezone|home_city|travel_count|\n",
      "+-----+-----------+-------------------+-------------------+---------+------------+\n",
      "| 2509| Cranbourne|               null|Australia/Melbourne|     null|           2|\n",
      "| 2529| Cranbourne|               null|Australia/Melbourne|     null|           1|\n",
      "| 5409|      Perth|               null|    Australia/Perth|     null|           3|\n",
      "| 9715|     Darwin|               null|   Australia/Darwin|     null|           1|\n",
      "|13460|  Newcastle|2022-03-04 03:30:02|   Australia/Sydney|     null|           1|\n",
      "|15322|   Maitland|               null|   Australia/Sydney|     null|           5|\n",
      "|15663|     Sydney|               null|   Australia/Sydney|     null|           3|\n",
      "|17979|   Brisbane|               null| Australia/Brisbane|     null|           1|\n",
      "|18628|   Brisbane|               null| Australia/Brisbane|     null|           1|\n",
      "|27469|     Mackay|2022-02-26 03:14:35| Australia/Brisbane|     null|           1|\n",
      "|27563|   Maitland|2022-03-03 05:09:42|   Australia/Sydney|     null|           1|\n",
      "|30421|    Bendigo|               null|Australia/Melbourne|     null|           3|\n",
      "|30428|  Toowoomba|               null| Australia/Brisbane|     null|           2|\n",
      "|30928|  Melbourne|               null|Australia/Melbourne|     null|           2|\n",
      "|31156|      Perth|2022-02-28 08:32:12|    Australia/Perth|     null|           1|\n",
      "|32954| Launceston|               null|   Australia/Hobart|     null|           1|\n",
      "|33013|   Canberra|               null|   Australia/Sydney|     null|           4|\n",
      "|35253|     Cairns|               null| Australia/Brisbane|     null|           1|\n",
      "|36103|Rockhampton|2022-03-04 07:28:57| Australia/Brisbane|     null|           1|\n",
      "|38510|  Newcastle|               null|   Australia/Sydney|     null|           1|\n",
      "+-----+-----------+-------------------+-------------------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "view_1_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ef356",
   "metadata": {},
   "source": [
    "## Создать витрину в разрезе зон"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98815b1a",
   "metadata": {},
   "source": [
    "Нужно создать геослой — найти распределение атрибутов, связанных с событиями, по географическим зонам (городам). Если проанализировать этот слой, то можно понять поведение пользователей по различным регионам. \n",
    "Итак, нам нужно посчитать количество событий в конкретном городе за неделю и месяц. Значит, витрина будет содержать следующие поля:\n",
    "* month — месяц расчёта;\n",
    "* week — неделя расчёта;\n",
    "* zone_id — идентификатор зоны (города) (не понял как реализовать по всем событиям, ведь координаты есть только у сообщений);\n",
    "* week_message — количество сообщений за неделю;\n",
    "* week_reaction — количество реакций за неделю;\n",
    "* week_subscription — количество подписок за неделю;\n",
    "* week_user — количество регистраций за неделю;\n",
    "* month_message — количество сообщений за месяц;\n",
    "* month_reaction — количество реакций за месяц;\n",
    "* month_subscription — количество подписок за месяц;\n",
    "* month_user — количество регистраций за месяц.\n",
    "\n",
    "В этой витрине мы учитываем не только отправленные сообщения, но и другие действия — подписки, реакции, регистрации (рассчитываются по первым событиям). Пока присвойте таким событиям координаты последнего отправленного сообщения конкретного пользователя (не понятен смысл - если данных нет, то и не стоит такую процедуру проводить, ведь это некорректно)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e42548b",
   "metadata": {},
   "source": [
    "**Прочитаем данные с реакциями:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b060324",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------------------+------------------+----------+\n",
      "|               event|event_type|                lat|               lon|      date|\n",
      "+--------------------+----------+-------------------+------------------+----------+\n",
      "|[,, 2022-03-05 07...|  reaction| -34.40351927336887|149.73577109555941|2022-03-05|\n",
      "|[,, 2022-03-05 02...|  reaction|-34.337548200603415|151.82208788269017|2022-03-05|\n",
      "|[,, 2022-03-05 06...|  reaction| -32.42359274527981| 151.8693407546899|2022-03-05|\n",
      "|[,, 2022-03-05 21...|  reaction| -40.58692145613617|148.00070631827495|2022-03-05|\n",
      "|[,, 2022-03-05 14...|  reaction| -26.91385555002475| 152.7788734092017|2022-03-05|\n",
      "|[,, 2022-03-05 03...|  reaction| -36.88399210892872| 143.9241145053058|2022-03-05|\n",
      "|[,, 2022-03-05 14...|  reaction|-41.067136060691745|147.64318158681752|2022-03-05|\n",
      "|[,, 2022-03-05 09...|  reaction| -40.83507535253652|147.30911595711027|2022-03-05|\n",
      "|[,, 2022-03-05 10...|  reaction|  -34.3785561468774|149.95163586950872|2022-03-05|\n",
      "|[,, 2022-03-05 23...|  reaction| -33.30305062050781|152.02541809406617|2022-03-05|\n",
      "|[,, 2022-03-05 06...|  reaction|-27.035336729221438|152.54906108713143|2022-03-05|\n",
      "|[,, 2022-03-05 17...|  reaction| -27.04212039727955|153.38682672335145|2022-03-05|\n",
      "|[,, 2022-03-05 00...|  reaction| -37.95171381088242|145.65011382502092|2022-03-05|\n",
      "|[,, 2022-03-05 20...|  reaction|-34.756513522701944| 139.6006595343272|2022-03-05|\n",
      "|[,, 2022-03-05 21...|  reaction|-11.964980821148417| 130.8614236521105|2022-03-05|\n",
      "|[,, 2022-03-05 20...|  reaction| -36.21500506587812|  144.358226875183|2022-03-05|\n",
      "|[,, 2022-03-05 01...|  reaction| -33.32924169401002|116.04460996602901|2022-03-05|\n",
      "|[,, 2022-03-05 13...|  reaction| -34.05341568228075| 138.9754883889735|2022-03-05|\n",
      "|[,, 2022-03-05 10...|  reaction|-36.748128114361414|143.86519273610398|2022-03-05|\n",
      "|[,, 2022-03-05 11...|  reaction|-22.711717896297028|150.84035957664722|2022-03-05|\n",
      "+--------------------+----------+-------------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- event: struct (nullable = true)\n",
      " |    |-- admins: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- channel_id: long (nullable = true)\n",
      " |    |-- datetime: string (nullable = true)\n",
      " |    |-- media: struct (nullable = true)\n",
      " |    |    |-- media_type: string (nullable = true)\n",
      " |    |    |-- src: string (nullable = true)\n",
      " |    |-- message: string (nullable = true)\n",
      " |    |-- message_channel_to: long (nullable = true)\n",
      " |    |-- message_from: long (nullable = true)\n",
      " |    |-- message_group: long (nullable = true)\n",
      " |    |-- message_id: long (nullable = true)\n",
      " |    |-- message_to: long (nullable = true)\n",
      " |    |-- message_ts: string (nullable = true)\n",
      " |    |-- reaction_from: string (nullable = true)\n",
      " |    |-- reaction_type: string (nullable = true)\n",
      " |    |-- subscription_channel: long (nullable = true)\n",
      " |    |-- subscription_user: string (nullable = true)\n",
      " |    |-- tags: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- user: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date = '2022-03-05'\n",
    "depth = 10\n",
    "\n",
    "act_period = input_paths(date, depth)\n",
    "reactions = spark.read\\\n",
    "    .option(\"basePath\", \"/user/master/data/geo/events\")\\\n",
    "    .parquet(*act_period)\\\n",
    "    .where(\"event_type='reaction'\")\n",
    "\n",
    "\n",
    "reactions.show()\n",
    "reactions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d959e0",
   "metadata": {},
   "source": [
    "Добавим недели и месяцы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11db25a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+----------+-----+----+\n",
      "|  user|reaction|event_type|      date|month|week|\n",
      "+------+--------+----------+----------+-----+----+\n",
      "|161701|    like|  reaction|2022-03-05|    3|   9|\n",
      "| 22300|    like|  reaction|2022-03-05|    3|   9|\n",
      "| 74850|    like|  reaction|2022-03-05|    3|   9|\n",
      "|112795|    like|  reaction|2022-03-05|    3|   9|\n",
      "|149167|    like|  reaction|2022-03-05|    3|   9|\n",
      "| 93858| dislike|  reaction|2022-03-05|    3|   9|\n",
      "|123349|    like|  reaction|2022-03-05|    3|   9|\n",
      "| 65468|    like|  reaction|2022-03-05|    3|   9|\n",
      "|137735|    like|  reaction|2022-03-05|    3|   9|\n",
      "| 16417|    like|  reaction|2022-03-05|    3|   9|\n",
      "|168213| dislike|  reaction|2022-03-05|    3|   9|\n",
      "|  2361|    like|  reaction|2022-03-05|    3|   9|\n",
      "|134467|    like|  reaction|2022-03-05|    3|   9|\n",
      "| 96196|    like|  reaction|2022-03-05|    3|   9|\n",
      "|105420|    like|  reaction|2022-03-05|    3|   9|\n",
      "| 60311|    like|  reaction|2022-03-05|    3|   9|\n",
      "|149545| dislike|  reaction|2022-03-05|    3|   9|\n",
      "| 93630|    like|  reaction|2022-03-05|    3|   9|\n",
      "| 33876| dislike|  reaction|2022-03-05|    3|   9|\n",
      "| 76612|    like|  reaction|2022-03-05|    3|   9|\n",
      "+------+--------+----------+----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reactions = reactions\\\n",
    "    .where(\"event_type='reaction'\")\\\n",
    "    .select(F.col(\"event.reaction_from\").alias(\"user\"),\n",
    "                F.col(\"event.reaction_type\").alias(\"reaction\"),\n",
    "                F.col(\"event_type\").alias(\"event_type\"),\n",
    "                F.col(\"date\").alias(\"date\"))\\\n",
    "    .withColumn(\"month\", F.month(\"date\"))\\\n",
    "    .withColumn(\"week\", F.weekofyear(\"date\"))\n",
    "\n",
    "df_reactions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406d340",
   "metadata": {},
   "source": [
    "Посчитаем количество реакций по каждому месяцу и по каждой неделе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78aec490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------------+--------------+\n",
      "|month|week|week_reaction|month_reaction|\n",
      "+-----+----+-------------+--------------+\n",
      "|    3|   9|       294376|        248424|\n",
      "|    2|   9|       294376|        216501|\n",
      "|    2|   8|       170549|        216501|\n",
      "+-----+----+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reactions_months = df_reactions.groupBy(F.col('month')).count().withColumnRenamed('count', 'month_reaction')\n",
    "\n",
    "df_reactions_weeks = df_reactions.groupBy(F.col('week')).count().withColumnRenamed('count', 'week_reaction')\n",
    "\n",
    "df_reactions_count = df_reactions.join(df_reactions_months, df_reactions.month == df_reactions_months.month, how='left')\\\n",
    "                    .join(df_reactions_weeks, df_reactions.week == df_reactions_weeks.week, how='left')\\\n",
    "                    .drop(df_reactions_months.month).drop(df_reactions_weeks.week)\\\n",
    "                    .select('month', 'week', 'week_reaction', 'month_reaction').distinct()\n",
    "\n",
    "df_reactions_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3816f7",
   "metadata": {},
   "source": [
    "**Прочитаем данные с подписками:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0271b01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-------------------+------------------+----------+\n",
      "|               event|  event_type|                lat|               lon|      date|\n",
      "+--------------------+------------+-------------------+------------------+----------+\n",
      "|[,, 2022-03-05 00...|subscription| -33.45530692004778|151.31543948420796|2022-03-05|\n",
      "|[,, 2022-03-05 22...|subscription|-40.862888495361425| 147.6596654521476|2022-03-05|\n",
      "|[,, 2022-03-05 22...|subscription|-33.714449927818805|151.28239873476585|2022-03-05|\n",
      "|[,, 2022-03-05 16...|subscription| -26.64637836118689|153.40176733828957|2022-03-05|\n",
      "|[,, 2022-03-05 13...|subscription| -37.53900430225147| 145.8137118521069|2022-03-05|\n",
      "|[,, 2022-03-05 03...|subscription| -34.09196608676216| 151.4613360983361|2022-03-05|\n",
      "|[,, 2022-03-05 07...|subscription| -31.29565679668916|116.80059062289207|2022-03-05|\n",
      "|[,, 2022-03-05 04...|subscription|-18.805026525396517|147.02422192497784|2022-03-05|\n",
      "|[,, 2022-03-05 21...|subscription| -34.18069062699671|151.55175750552164|2022-03-05|\n",
      "|[,, 2022-03-05 08...|subscription|-32.611288966211745|116.39352958059476|2022-03-05|\n",
      "|[,, 2022-03-05 09...|subscription|-27.412490699853315|152.49250954674957|2022-03-05|\n",
      "|[,, 2022-03-05 05...|subscription|  -40.8306548398256|147.86139255664858|2022-03-05|\n",
      "|[,, 2022-03-05 19...|subscription|-23.371878086391376| 150.7841747161511|2022-03-05|\n",
      "|[,, 2022-03-05 15...|subscription| -42.62630911279349|147.97386998250403|2022-03-05|\n",
      "|[,, 2022-03-05 00...|subscription| -37.81110143753855|145.60893813608212|2022-03-05|\n",
      "|[,, 2022-03-05 23...|subscription|-35.178678868834275|149.31571197959502|2022-03-05|\n",
      "|[,, 2022-03-05 00...|subscription| -33.64270774254109|151.32389576766585|2022-03-05|\n",
      "|[,, 2022-03-05 08...|subscription|  -34.5504000899879|149.74185952033076|2022-03-05|\n",
      "|[,, 2022-03-05 05...|subscription| -32.86165896159122|152.64538034389642|2022-03-05|\n",
      "|[,, 2022-03-05 09...|subscription|-16.686160265429933|145.96491224567538|2022-03-05|\n",
      "+--------------------+------------+-------------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- event: struct (nullable = true)\n",
      " |    |-- admins: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- channel_id: long (nullable = true)\n",
      " |    |-- datetime: string (nullable = true)\n",
      " |    |-- media: struct (nullable = true)\n",
      " |    |    |-- media_type: string (nullable = true)\n",
      " |    |    |-- src: string (nullable = true)\n",
      " |    |-- message: string (nullable = true)\n",
      " |    |-- message_channel_to: long (nullable = true)\n",
      " |    |-- message_from: long (nullable = true)\n",
      " |    |-- message_group: long (nullable = true)\n",
      " |    |-- message_id: long (nullable = true)\n",
      " |    |-- message_to: long (nullable = true)\n",
      " |    |-- message_ts: string (nullable = true)\n",
      " |    |-- reaction_from: string (nullable = true)\n",
      " |    |-- reaction_type: string (nullable = true)\n",
      " |    |-- subscription_channel: long (nullable = true)\n",
      " |    |-- subscription_user: string (nullable = true)\n",
      " |    |-- tags: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- user: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date = '2022-03-05'\n",
    "depth = 10\n",
    "\n",
    "act_period = input_paths(date, depth)\n",
    "subscriptions = spark.read\\\n",
    "    .option(\"basePath\", \"/user/master/data/geo/events\")\\\n",
    "    .parquet(*act_period)\\\n",
    "    .where(\"event_type='subscription'\")\n",
    "\n",
    "\n",
    "subscriptions.show()\n",
    "subscriptions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec79c65",
   "metadata": {},
   "source": [
    "Добавим недели и месяцы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a18208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+----------+-----+----+\n",
      "|  user|channel|  event_type|      date|month|week|\n",
      "+------+-------+------------+----------+-----+----+\n",
      "|121730| 604773|subscription|2022-03-05|    3|   9|\n",
      "|121820| 652956|subscription|2022-03-05|    3|   9|\n",
      "| 12245| 818823|subscription|2022-03-05|    3|   9|\n",
      "|126012| 934801|subscription|2022-03-05|    3|   9|\n",
      "|126737|  47149|subscription|2022-03-05|    3|   9|\n",
      "|127358| 614046|subscription|2022-03-05|    3|   9|\n",
      "|129400| 324833|subscription|2022-03-05|    3|   9|\n",
      "|129478| 528251|subscription|2022-03-05|    3|   9|\n",
      "|135532| 245006|subscription|2022-03-05|    3|   9|\n",
      "| 13645| 203410|subscription|2022-03-05|    3|   9|\n",
      "| 14190| 952262|subscription|2022-03-05|    3|   9|\n",
      "|143626| 275105|subscription|2022-03-05|    3|   9|\n",
      "|143915| 456879|subscription|2022-03-05|    3|   9|\n",
      "|145020| 153776|subscription|2022-03-05|    3|   9|\n",
      "|148207| 278093|subscription|2022-03-05|    3|   9|\n",
      "|151378| 738179|subscription|2022-03-05|    3|   9|\n",
      "|151385| 687922|subscription|2022-03-05|    3|   9|\n",
      "|154234|  97766|subscription|2022-03-05|    3|   9|\n",
      "|154645| 151596|subscription|2022-03-05|    3|   9|\n",
      "|155001|  62475|subscription|2022-03-05|    3|   9|\n",
      "+------+-------+------------+----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_subscriptions = subscriptions\\\n",
    "    .where(\"event_type='subscription'\")\\\n",
    "    .select(F.col(\"event.user\").alias(\"user\"),\n",
    "                F.col(\"event.subscription_channel\").alias(\"channel\"),\n",
    "                F.col(\"event_type\").alias(\"event_type\"),\n",
    "                F.col(\"date\").alias(\"date\"))\\\n",
    "    .withColumn(\"month\", F.month(\"date\"))\\\n",
    "    .withColumn(\"week\", F.weekofyear(\"date\"))\n",
    "\n",
    "df_subscriptions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ff08e",
   "metadata": {},
   "source": [
    "Посчитаем количество подписок по каждому месяцу и по каждой неделе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eca80123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------------+------------------+\n",
      "|month|week|week_subscription|month_subscription|\n",
      "+-----+----+-----------------+------------------+\n",
      "|    2|   9|           559262|            413952|\n",
      "|    3|   9|           559262|            471341|\n",
      "|    2|   8|           326031|            413952|\n",
      "+-----+----+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_subscriptions_months = df_subscriptions.groupBy(F.col('month')).count().withColumnRenamed('count', 'month_subscription')\n",
    "\n",
    "df_subscriptions_weeks = df_subscriptions.groupBy(F.col('week')).count().withColumnRenamed('count', 'week_subscription')\n",
    "\n",
    "df_subscriptions_count = df_subscriptions\\\n",
    "                    .join(df_subscriptions_months, df_subscriptions.month == df_subscriptions_months.month, how='left')\\\n",
    "                    .join(df_subscriptions_weeks, df_subscriptions.week == df_subscriptions_weeks.week, how='left')\\\n",
    "                    .drop(df_subscriptions_months.month).drop(df_subscriptions_weeks.week)\\\n",
    "                    .select('month', 'week', 'week_subscription', 'month_subscription').distinct()\n",
    "\n",
    "df_subscriptions_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d53fbb",
   "metadata": {},
   "source": [
    "**Прочитаем данные с сообщениями:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d95c1b21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------------------+------------------+----------+\n",
      "|               event|event_type|                lat|               lon|      date|\n",
      "+--------------------+----------+-------------------+------------------+----------+\n",
      "|[,,,, i dont know...|   message| -33.70134197376076|152.15214334618787|2022-03-05|\n",
      "|[[43081], 989107,...|   message|-32.817112404689226|152.04366515140228|2022-03-05|\n",
      "|[,,,, is this the...|   message|-16.799098293427118|146.27308763602898|2022-03-05|\n",
      "|[[34265], 69433, ...|   message| -32.81332035813615|115.89214218896626|2022-03-04|\n",
      "|[,,,, please,, 46...|   message| -32.21426067817561|152.17841332537947|2022-03-04|\n",
      "|[[123339], 657862...|   message| -36.85292468522662|  145.705396090251|2022-03-04|\n",
      "|[,,,, where can I...|   message|-41.083056615424475|147.44592025888363|2022-03-04|\n",
      "|[,,,, anybody kno...|   message|-33.684325210832576|151.20298931356814|2022-03-03|\n",
      "|[,,,, i have just...|   message|  -40.5104640690403|147.59769275817007|2022-03-03|\n",
      "|[,,,, Thanks! I'v...|   message|-26.646587010769966|153.65634260465546|2022-03-03|\n",
      "|[[56006], 188350,...|   message|-31.875864677402035| 152.2841586408504|2022-03-02|\n",
      "|[,,,, no,, 149967...|   message|  -27.3601181073781|153.49280841697237|2022-03-02|\n",
      "|[[165987], 880185...|   message|-12.323870300499514|130.96794538948419|2022-03-02|\n",
      "|[,,,, get the dat...|   message| -37.75127160647003|145.89643263016387|2022-03-01|\n",
      "|[,,,, 10.04,, 317...|   message| -40.83950115228069|147.40531624147673|2022-03-01|\n",
      "|[,,,, is it possi...|   message|  -33.9356612884829|139.33558916801803|2022-03-01|\n",
      "|[,,,, How do I cr...|   message| -27.93449228266315| 154.2640987701025|2022-03-01|\n",
      "|[,,,, crashed?,, ...|   message| -22.44271764174707|151.47007897729503|2022-03-01|\n",
      "|[,,,, can anyone ...|   message|-27.087137251495164|152.31836777193618|2022-03-01|\n",
      "|[,,,, is it safe ...|   message|-36.537466711716974|145.06230618782718|2022-03-01|\n",
      "+--------------------+----------+-------------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- event: struct (nullable = true)\n",
      " |    |-- admins: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- channel_id: long (nullable = true)\n",
      " |    |-- datetime: string (nullable = true)\n",
      " |    |-- media: struct (nullable = true)\n",
      " |    |    |-- media_type: string (nullable = true)\n",
      " |    |    |-- src: string (nullable = true)\n",
      " |    |-- message: string (nullable = true)\n",
      " |    |-- message_channel_to: long (nullable = true)\n",
      " |    |-- message_from: long (nullable = true)\n",
      " |    |-- message_group: long (nullable = true)\n",
      " |    |-- message_id: long (nullable = true)\n",
      " |    |-- message_to: long (nullable = true)\n",
      " |    |-- message_ts: string (nullable = true)\n",
      " |    |-- reaction_from: string (nullable = true)\n",
      " |    |-- reaction_type: string (nullable = true)\n",
      " |    |-- subscription_channel: long (nullable = true)\n",
      " |    |-- subscription_user: string (nullable = true)\n",
      " |    |-- tags: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- user: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "date = '2022-03-05'\n",
    "depth = 10\n",
    "\n",
    "act_period = input_paths(date, depth)\n",
    "messages = spark.read\\\n",
    "    .option(\"basePath\", \"/user/master/data/geo/events\")\\\n",
    "    .parquet(*act_period)\\\n",
    "    .where(\"event_type='message'\")\n",
    "\n",
    "messages.show()\n",
    "messages.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa665d24",
   "metadata": {},
   "source": [
    "Добавим недели и месяцы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a77a76b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+----------+-----+----+\n",
      "|  user|message|event_type|      date|month|week|\n",
      "+------+-------+----------+----------+-----+----+\n",
      "|  7240| 672513|   message|2022-03-05|    3|   9|\n",
      "| 43081|1117752|   message|2022-03-05|    3|   9|\n",
      "| 58776| 227124|   message|2022-03-05|    3|   9|\n",
      "| 34265|1091227|   message|2022-03-04|    3|   9|\n",
      "| 46129| 803362|   message|2022-03-04|    3|   9|\n",
      "|123339|1114280|   message|2022-03-04|    3|   9|\n",
      "|135981| 168314|   message|2022-03-04|    3|   9|\n",
      "| 59630|  50082|   message|2022-03-03|    3|   9|\n",
      "| 61619| 699867|   message|2022-03-03|    3|   9|\n",
      "|141584| 266714|   message|2022-03-03|    3|   9|\n",
      "| 56006|1105146|   message|2022-03-02|    3|   9|\n",
      "|149967| 974437|   message|2022-03-02|    3|   9|\n",
      "|165987|1127525|   message|2022-03-02|    3|   9|\n",
      "| 31760| 191443|   message|2022-03-01|    3|   9|\n",
      "| 31760| 483238|   message|2022-03-01|    3|   9|\n",
      "| 46832|1010661|   message|2022-03-01|    3|   9|\n",
      "| 62385| 199710|   message|2022-03-01|    3|   9|\n",
      "| 62385| 261118|   message|2022-03-01|    3|   9|\n",
      "| 94847| 588082|   message|2022-03-01|    3|   9|\n",
      "|108315| 270081|   message|2022-03-01|    3|   9|\n",
      "+------+-------+----------+----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_messages = messages\\\n",
    "    .where(\"event_type='message'\")\\\n",
    "    .select(F.col(\"event.message_from\").alias(\"user\"),\n",
    "                F.col(\"event.message_id\").alias(\"message\"),\n",
    "                F.col(\"event_type\").alias(\"event_type\"),\n",
    "                F.col(\"date\").alias(\"date\"))\\\n",
    "    .withColumn(\"month\", F.month(\"date\"))\\\n",
    "    .withColumn(\"week\", F.weekofyear(\"date\"))\n",
    "\n",
    "df_messages.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a601e7",
   "metadata": {},
   "source": [
    "Посчитаем количество сообщений по каждому месяцу и по каждой неделе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eca96d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------------+-------------+\n",
      "|month|week|week_message|month_message|\n",
      "+-----+----+------------+-------------+\n",
      "|    2|   9|       33905|        28057|\n",
      "|    2|   8|       22442|        28057|\n",
      "|    3|   9|       33905|        28290|\n",
      "+-----+----+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_messages_months = df_messages.groupBy(F.col('month')).count().withColumnRenamed('count', 'month_message')\n",
    "\n",
    "df_messages_weeks = df_messages.groupBy(F.col('week')).count().withColumnRenamed('count', 'week_message')\n",
    "\n",
    "df_messages_count = df_messages\\\n",
    "                    .join(df_messages_months, df_messages.month == df_messages_months.month, how='left')\\\n",
    "                    .join(df_messages_weeks, df_messages.week == df_messages_weeks.week, how='left')\\\n",
    "                    .drop(df_messages_months.month).drop(df_messages_weeks.week)\\\n",
    "                    .select('month', 'week', 'week_message', 'month_message').distinct()\n",
    "\n",
    "df_messages_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a38d1",
   "metadata": {},
   "source": [
    "1. Объединим данные по сообщениям, реакциям и подпискам, чтобы найти самое раннее событие для пользователя - это будет считаться регистрацией.\n",
    "2. Посчитаем количество регистраций по месяцам и по неделям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4ea4ac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------+----------+\n",
      "|month|week|week_user|month_user|\n",
      "+-----+----+---------+----------+\n",
      "|    2|   9|    14024|    160950|\n",
      "|    3|   9|    14024|      8100|\n",
      "|    2|   8|   155026|    160950|\n",
      "+-----+----+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_users = df_reactions.select('user', 'event_type', 'date', 'month', 'week')\\\n",
    "            .union(df_subscriptions.select('user', 'event_type', 'date', 'month', 'week'))\\\n",
    "            .union(df_messages.select('user', 'event_type', 'date', 'month', 'week')).distinct()\n",
    "\n",
    "window_users = Window().partitionBy('user').orderBy('date')\n",
    "\n",
    "df_window_users_reg = df_users.withColumn(\"rank_date\", F.row_number().over(window_users))\n",
    "\n",
    "df_users_reg = df_window_users_reg.select('user', 'month', 'week').where(\"rank_date = 1\")\n",
    "\n",
    "df_users_months = df_users_reg.groupBy(F.col('month')).count().withColumnRenamed('count', 'month_user')\n",
    "\n",
    "df_users_weeks = df_users_reg.groupBy(F.col('week')).count().withColumnRenamed('count', 'week_user')\n",
    "\n",
    "df_users_count = df_users_reg\\\n",
    "                    .join(df_users_months, df_users_reg.month == df_users_months.month, how='left')\\\n",
    "                    .join(df_users_weeks, df_users_reg.week == df_users_weeks.week, how='left')\\\n",
    "                    .drop(df_users_months.month).drop(df_users_weeks.week)\\\n",
    "                    .select('month', 'week', 'week_user', 'month_user').distinct()\n",
    "\n",
    "df_users_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940bfa6b",
   "metadata": {},
   "source": [
    "Объединим все полученные таблицы по количеству событий и получим необходимую витрину:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d010877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_messages = [df_users_count.month == df_messages_count.month, df_users_count.week == df_messages_count.week]\n",
    "cond_subscriptions = [df_users_count.month == df_subscriptions_count.month, df_users_count.week == df_subscriptions_count.week]\n",
    "cond_reactions = [df_users_count.month == df_reactions_count.month, df_users_count.week == df_reactions_count.week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e75503d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------+----------+------------+-------------+-----------------+------------------+-------------+--------------+\n",
      "|month|week|week_user|month_user|week_message|month_message|week_subscription|month_subscription|week_reaction|month_reaction|\n",
      "+-----+----+---------+----------+------------+-------------+-----------------+------------------+-------------+--------------+\n",
      "|    2|   9|    14024|    160950|       33905|        28057|           559262|            413952|       294376|        216501|\n",
      "|    3|   9|    14024|      8100|       33905|        28290|           559262|            471341|       294376|        248424|\n",
      "|    2|   8|   155026|    160950|       22442|        28057|           326031|            413952|       170549|        216501|\n",
      "+-----+----+---------+----------+------------+-------------+-----------------+------------------+-------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "view_2 = df_users_count\\\n",
    "        .join(df_messages_count, cond_messages)\\\n",
    "        .join(df_subscriptions_count, cond_subscriptions)\\\n",
    "        .join(df_reactions_count, cond_reactions)\\\n",
    "        .drop(df_messages_count.month).drop(df_messages_count.week)\\\n",
    "        .drop(df_subscriptions_count.month).drop(df_subscriptions_count.week)\\\n",
    "        .drop(df_reactions_count.month).drop(df_reactions_count.week)\n",
    "\n",
    "view_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ff50f",
   "metadata": {},
   "source": [
    "## Построить витрину для рекомендации друзей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095a23e",
   "metadata": {},
   "source": [
    "Как будет работать рекомендация друзей: если пользователи подписаны на один канал, ранее никогда не переписывались и расстояние между ними не превышает 1 км, то им обоим будет предложено добавить другого в друзья. Образовывается парный атрибут, который обязан быть уникальным: порядок упоминания не должен создавать дубли пар.\n",
    "Витрина будет содержать следующие атрибуты:\n",
    "* user_left — первый пользователь;\n",
    "* user_right — второй пользователь;\n",
    "* processed_dttm — дата расчёта витрины (не реализовал, не пойму как);\n",
    "* zone_id — идентификатор зоны (города);\n",
    "* local_time — локальное время (не уверен, что реализовал правильно)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c3e5c",
   "metadata": {},
   "source": [
    "Добавим в первую витрину информацию о подписках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "993acef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_3 = view_1_1.join(df_subscriptions, view_1_1.user == df_subscriptions.user)\\\n",
    "                    .drop(df_subscriptions.user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca962a99",
   "metadata": {},
   "source": [
    "Создадим копию полученной таблицы и объединим их с условием, что город и группа подписки совпадает, но пользователь другой - таким образом у нас произойдет объединение по пользователям, которых можно рекомендовать друг другу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9efd351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 223:====================================================>(198 + 2) / 200]105]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-------------------+\n",
      "|user_left|user_right| zone_id|         local_time|\n",
      "+---------+----------+--------+-------------------+\n",
      "|   104017|    129061|Adelaide| Australia/Adelaide|\n",
      "|   129061|    104017|Adelaide| Australia/Adelaide|\n",
      "|    85592|    120651|Adelaide| Australia/Adelaide|\n",
      "|    85592|    147175|Adelaide| Australia/Adelaide|\n",
      "|   120651|     85592|Adelaide| Australia/Adelaide|\n",
      "|   120651|    147175|Adelaide| Australia/Adelaide|\n",
      "|   147175|    120651|Adelaide| Australia/Adelaide|\n",
      "|   147175|     85592|Adelaide| Australia/Adelaide|\n",
      "|    63399|    141465|Adelaide| Australia/Adelaide|\n",
      "|   141465|     63399|Adelaide| Australia/Adelaide|\n",
      "|    36868|    104875|Adelaide| Australia/Adelaide|\n",
      "|   104875|     36868|Adelaide| Australia/Adelaide|\n",
      "|   138054|     24264|Adelaide| Australia/Adelaide|\n",
      "|    24264|    138054|Adelaide| Australia/Adelaide|\n",
      "|    79678|    117504|Adelaide| Australia/Adelaide|\n",
      "|   117504|     79678|Adelaide| Australia/Adelaide|\n",
      "|   154756|     42734| Bendigo|Australia/Melbourne|\n",
      "|    42734|    154756| Bendigo|Australia/Melbourne|\n",
      "|    61091|     84200| Bendigo|Australia/Melbourne|\n",
      "|    84200|     61091| Bendigo|Australia/Melbourne|\n",
      "+---------+----------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "view_3_copy = view_3.withColumnRenamed(\"user\", \"user_right\")\n",
    "\n",
    "cond_view_3 = [view_3.act_city == view_3_copy.act_city,\n",
    "               view_3.channel == view_3_copy.channel,\n",
    "               view_3.user != view_3_copy.user_right]\n",
    "\n",
    "view_3_1 = view_3.join(view_3_copy, cond_view_3)\\\n",
    "        .drop(view_3_copy.act_city)\\\n",
    "        .drop(view_3_copy.TIME_UTC)\\\n",
    "        .drop(view_3_copy.timezone)\\\n",
    "        .drop(view_3_copy.home_city)\\\n",
    "        .drop(view_3_copy.travel_count)\n",
    "\n",
    "view_3_2 = view_3_1.select('user', 'user_right', 'act_city', 'timezone')\\\n",
    "            .withColumnRenamed(\"user\", \"user_left\")\\\n",
    "            .withColumnRenamed(\"act_city\", \"zone_id\")\\\n",
    "            .withColumnRenamed(\"timezone\", \"local_time\")\n",
    "\n",
    "view_3_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa91b2b",
   "metadata": {},
   "source": [
    "**Если дочитал до конца, спасибо! Сам знаю, что очень много недоработок, но с учетом, что инфраструктура работает с перебоями времени не хватило, да и желание этим заниматься в таких условиях пропало совсем.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7321a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0f250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ccb14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
